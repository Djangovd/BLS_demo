{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BLS Demo\n",
    "\n",
    "In this notebook we try to illustrate the BLS distributed key generation and verifiable randomness protocol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bn256\n",
    "import random\n",
    "import os\n",
    "import binascii\n",
    "import hashlib\n",
    "import collections\n",
    "import ecdsa\n",
    "import unittest\n",
    "import numpy as np\n",
    "from pypoly import Polynomial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization\n",
    " \n",
    "We introduce $N$ participants and use as our threshold $t$, where \n",
    "$N = 2n + 1 = n + (n + 1)$ and $t = n + 1$. $n$ is the degree of the polynomials \n",
    "  \n",
    "Here we are using the multiplicative representations (i.e. $a \\cdot G$), since this is in accordance with the corresponding algebra of elliptic curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10        # Degree of polynomial\n",
    "N = 2 * n + 1 # Number of users/participants\n",
    "t = n + 1     # Threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Necessary functions: batch 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Following three functions taken straight from the BN256 pairings code\n",
    "\n",
    "def bls_keygen():\n",
    "    k,g = bn256.g2_random()\n",
    "    return (k,g)\n",
    "\n",
    "def bls_sign(privkey, msg):\n",
    "    pt = bn256.g1_hash_to_point(msg)\n",
    "    assert pt.is_on_curve()\n",
    "\n",
    "    return bn256.g1_compress(pt.scalar_mul(privkey))\n",
    "\n",
    "def bls_verify(pubkey, msg, csig):\n",
    "    sig = bn256.g1_uncompress(csig)\n",
    "\n",
    "    assert type(pubkey) == bn256.curve_twist\n",
    "    assert type(sig) == bn256.curve_point\n",
    "\n",
    "    msg_pt = bn256.g1_hash_to_point(msg)\n",
    "\n",
    "    assert msg_pt.is_on_curve()\n",
    "\n",
    "    v1 = bn256.optimal_ate(pubkey, msg_pt)\n",
    "    v2 = bn256.optimal_ate(bn256.twist_G, sig)\n",
    "\n",
    "    return v1 == v2\n",
    "\n",
    "####\n",
    "\n",
    "def mod_q(num): # q = order: order of G1, G2\n",
    "    qq = bn256.order\n",
    "    return pow(num, int(1), qq)\n",
    "\n",
    "####\n",
    "\n",
    "def generate_random_number(n=32) -> bytes: # Taken straight from someone else's notebook\n",
    "    \"\"\"Collect n bytes of random data.\n",
    "\n",
    "    Temporary implementation since os.urandom might be not safe enough!\n",
    "    The quality of the randomness depends on the OS implementation.\n",
    "    \"\"\"\n",
    "    return os.urandom(n)\n",
    "\n",
    "#####\n",
    "\n",
    "def rnd_poly_coeffs(d):\n",
    "    # Retruns random coefficients for a polynomial of degree d\n",
    "    a = [ int.from_bytes(generate_random_number(), 'little')  for i in range(d+1)]\n",
    "    return a\n",
    "\n",
    "def poly(coeffs, x): # Calculate individual terms of the form coeff_j * x^j as well as the sum p(x) = coeff_0 + ... coeff_n * x^n\n",
    "    terms = [ coeffs[j] * x**j for j in range(len(coeffs)) ]\n",
    "    s = 0\n",
    "    for term in terms:\n",
    "        s += term\n",
    "    return terms, s "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Necessary functions: batch 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def lagrange_coeff(i, lst, t): # Lagrange coefficients, used for Lagrange interpolation\n",
    "    assert (t == len(lst))\n",
    "    parts = [j+1 for j in lst] # j is the array index, j+i the participant ID\n",
    "    idx_i = parts.index(i+1)\n",
    "    parts.pop(idx_i)\n",
    "    prod = 1\n",
    "    for j in parts:\n",
    "        denom = pow( j - (i+1), bn256.order - 2, bn256.order)\n",
    "        prod *= mod_q(j * denom)\n",
    "    return mod_q(prod)\n",
    "    \n",
    "# Introducing the generators\n",
    "G1 = bn256.curve_G # Generator of EC1\n",
    "G2 = bn256.twist_G # Generator of EC2\n",
    "\n",
    "def G2mult(coeff): # Multiply generator of curve 2 (G2) by an integer\n",
    "    return bn256.g2_scalar_base_mult(coeff)\n",
    "\n",
    "def G2mult2(coeff_list): # Create list made of generator of curve 2 (G2) multiplied by integers in coeff_list\n",
    "    return [ bn256.g2_scalar_base_mult(coeff) for coeff in coeff_list ]\n",
    "\n",
    "def AnyG1Pointmult(AG1,x): # Multiply general points on curve 1 A*G1 with another integer scalar x \n",
    "    if x < 0:\n",
    "        #return AnyG1Pointmult(AG1.inverse(), int(abs(x)))\n",
    "        return AnyG1Pointmult(AG1, bn256.order - int(x))\n",
    "    else:\n",
    "        return AG1.scalar_mul(x)\n",
    "\n",
    "def AnyG2Pointmult(AG2,x): # Multiply general points on curve 2 A*G2 with another integer scalar x \n",
    "    if x < 0:\n",
    "        #return AnyG2Pointmult(AG2.inverse(), int(abs(x)))\n",
    "        return AnyG2Pointmult(AG2, bn256.order - int(x))\n",
    "    else:\n",
    "        return AG2.scalar_mul(x)\n",
    "\n",
    "def recursive_g1_add(lst):  # Addition of points on curve 1. Done in this way because '+' operator doesn't work for EC points (in this package)\n",
    "    while len(lst) > 2:\n",
    "        sum_points = bn256.g1_add(lst[0], lst[1])\n",
    "        lst = lst[2:]\n",
    "        lst.append(sum_points)\n",
    "    if len(lst) == 2:\n",
    "        return bn256.g1_add(lst[0], lst[1])\n",
    "    else:\n",
    "        return lst[0]\n",
    "\n",
    "def recursive_g2_add(lst): # Addition of points on curve 2. Done in this way because '+' operator doesn't work for EC points (in this package)\n",
    "    while len(lst) > 2:\n",
    "        sum_points = bn256.g2_add(lst[0], lst[1])\n",
    "        lst = lst[2:]\n",
    "        lst.append(sum_points)\n",
    "    if len(lst) == 2:\n",
    "        return bn256.g2_add(lst[0], lst[1])\n",
    "    else:\n",
    "        return lst[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate keys and RND polynomials (coefficients)\n",
    "Calculate polynomial coefficients for each user's polynomial. They are of the form $\\text{RND}(n) \\leftarrow a_{ik}$, where $1 \\leq i \\leq N$ and $0 \\leq k \\leq t$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_poly = []\n",
    "for i in range(N): # Loop over users\n",
    "    P_poly.append(rnd_poly_coeffs(n)) # RND polynomial coefficients. dim = N x t\n",
    "    \n",
    "#print (\"P_poly rnd   = \", P_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare points and shares for exchanging\n",
    "\n",
    "Compute points $A_{ik} = a_{ik} \\cdot G_2$ and $s_{ij} = f_i(j) = \\sum_{k=0}^t a_{ik} \\cdot j^k \\cdot G_2$ to be shared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "AsG     = [] # List of lists. Each list contains the coefficients of the users (random) polynomial. Dimensions: N x t\n",
    "sij     = [] # sij's shared by each user. These are the s_ij = f_i(j). Dimensions: N x (N-1) \n",
    "sij_tmp = 0  # dummy variable\n",
    "ss      = []\n",
    "\n",
    "### Points for exchanging\n",
    "\n",
    "for i in range(N): # Loop over users\n",
    "    AsG.append(G2mult2(P_poly[i]))  # Terms of the form aik * G2. Dims: N x t\n",
    "    js = [j for j in range(1,N+1)] # j runs over participant IDs\n",
    "    sij = []\n",
    "    for j in js:\n",
    "        _, sij_tmp = poly(P_poly[i], j)\n",
    "        sij.append(sij_tmp)    # List containing s_ij = f_i(j), 0 <= i <= N-1, 1 <= j <= N\n",
    "    ss.append(sij)\n",
    "    \n",
    "#print (\"ss  = \", ss)\n",
    "#print (\"AsG = \", AsG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation\n",
    "At this stage the points $A_{ik} = a_{ik} \\cdot G_2$ have been distributed. Furthermore, participant $P_i$ has sent $s_{ij}$ to participant $P_j$.  \n",
    "Each participant can now calculate and check that $\\sum_{k=0}^t A_{ik} \\cdot j^k == s_{ij}$. This is what happens in the following two steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "AsGkterms = []\n",
    "AsGkterms_tmp = []\n",
    "\n",
    "for i in range(N): # Loop over users\n",
    "    js = [j for j in range(1,N+1) ] # j runs over participant IDs\n",
    "    AsGkterms_tmp = []\n",
    "    for j in js:        \n",
    "        AsGk_t_tmp = [ AnyG2Pointmult(AsG[i][k], j**k) for k in range(t) ] # Terms of the form j^k * aik * G2\n",
    "        AsGkterms_tmp.append(recursive_g2_add(AsGk_t_tmp)) # sum the terms above for each j\n",
    "    AsGkterms.append(AsGkterms_tmp)\n",
    "\n",
    "#print (\" A x G x j^k = \", AsGkterms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that $s_{ij} \\cdot G_2 == \\sum_k a_{ik} \\cdot j^k \\cdot G_2$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity check # 0\n",
      "Sanity check # 1\n",
      "Sanity check # 2\n",
      "Sanity check # 3\n",
      "Sanity check # 4\n",
      "Sanity check # 5\n",
      "Sanity check # 6\n"
     ]
    }
   ],
   "source": [
    "for i in range(N):    \n",
    "    rhs = AsGkterms[i] # RHS in Eqn. (1) in David's notes\n",
    "    lhs = G2mult2(ss[i]) # LHS in Eqn. (1) in David's notes\n",
    "    #unittest.TestCase.assertListEqual(lhs, rhs)\n",
    "    print (\"Sanity check #\", i)\n",
    "    #print (\"RHS  = \", rhs)    \n",
    "    #print (\"LHS  = \", lhs)\n",
    "    ok = (str(rhs) == str(lhs))\n",
    "    assert ok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating PubK and public verification Key\n",
    "\n",
    "The global public key can now be determined as: $\\text{PubK} = \\sum_i A_{i,0}$. The index $i \\in I_{\\text{QUAL}} \\subseteq \\{1, \\ldots, N \\}$.  \n",
    "Next, each participant, $i \\in I_{\\text{QUAL}}$ generates a secret key $x_j \\leftarrow \\sum_{i} s_{ij}$ of the shares that have been sent to her/him from $j \\in I_{\\text{QUAL}} \\backslash \\{i\\}$.  \n",
    "Lastly, each participant generates public validation keys: $VK_{j} = G_2 \\cdot x_j$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PKs = []\n",
    "for i in range(N):\n",
    "# We could/should play around with number of participants. Assuming not everyone being honest etc. \n",
    "# For now: QUAL = I = {1,.., N}\n",
    "    PKs.append(AsG[i][0])  \n",
    "\n",
    "PK = recursive_g2_add(PKs)\n",
    "#print (\"PK   = \", PK)\n",
    "\n",
    "# Individual secret keys\n",
    "xjs = []\n",
    "for j in range(N): # Loop over participants\n",
    "    xj = 0\n",
    "    for i in range(N): # Sum over participants in the QUAL group in David's notes\n",
    "        xj += ss[i][j]\n",
    "    xjs.append(xj) # list of secret keys\n",
    "\n",
    "#print (\"xj   = \", xjs)\n",
    "\n",
    "VKs  = []\n",
    "sumss = []\n",
    "testsum = []\n",
    "\n",
    "for j in range(N):\n",
    "    sumsij = 0\n",
    "    for i in range(N): # Sum over participants in the QUAL group in David's notes\n",
    "        sumsij += ss[i][j]\n",
    "    testsum.append(sumsij)\n",
    "    VKs.append(G2mult(sumsij))\n",
    "    \n",
    "#print (\"VK   = \", VKs)\n",
    "#print (\"tst  = \", testsum)\n",
    "assert (testsum == xjs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The participants create individual signatures\n",
    "\n",
    "Each of the participants computes $\\sigma_{r,i} = \\mathrm{Sign}(r ~||~ \\sigma_{r-1}, sk_{G,i})$. To begin with we create a message $\\text{msg}_{\\text{init}} = \\text{\"This is Fetch AI.\"}$, and subsequently hash it: $\\text{SHA}_{512}(\\text{msg}_{\\text{init}}) \\leftarrow \\text{msg}_{\\text{init}}$.  \n",
    "Next, signatures are created: $\\text{Sig}_{r, i} = \\text{BLS_sign}(sk_i, \\text{msg}_{\\text{init}})$.  \n",
    "  \n",
    "Please note, that here we calculate $\\sigma_{r,i} = \\mathrm{Sign}(\\sigma_{r-1}, sk_{G,i})$, i.e. we are not concatenating with the round ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use SHA512 for hashing\n",
    "sha = hashlib.sha512()\n",
    "\n",
    "msg_init = \"This is Fetch AI.\".encode(\"utf-8\")\n",
    "print(\"msg_init 1 : \", msg_init)\n",
    "\n",
    "#sha.update(msg_init)\n",
    "\n",
    "hash_msg_init = hashlib.sha512(b'This is Fetch AI.').hexdigest()\n",
    "\n",
    "print(\"msg_init 2 : \", hash_msg_init)\n",
    "\n",
    "sigs = [] # List containing signatures of participants\n",
    "\n",
    "# Init. Create array of signatures of the form: (i, sig_{r,i})\n",
    "for i in range(N):\n",
    "    sigs.append( (i, bls_sign(xjs[i], hash_msg_init.encode(\"utf-8\"))) )\n",
    "    \n",
    "#print (\"Sigs = \", sigs)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this stage, two more steps are necessary.  \n",
    "1) Use public $VK$'s to verify signatures  \n",
    "2) Compute group signature, combining $t$ of the signature shares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Verify each signature share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a test case: \n",
    "print(\"Sig[0][1]    = \", sigs[0][1])\n",
    "print(\"VK_0         = \", VKs[0])\n",
    "\n",
    "# Each signature share is verified using (public) verification keys:\n",
    "for i in range(N):\n",
    "    ok = bls_verify(VKs[i], hash_msg_init.encode(\"utf-8\"), sigs[i][1])\n",
    "    assert ok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Compute group signature, using $t$ signature shares\n",
    "\n",
    "Taking advantage of the threshold property, the combined signature is calculated: $\\sigma_{t} = \\sum_{i \\in \\{1, \\ldots, N \\} } \\lambda_i \\cdot \\sigma{i}$, where $\\lambda_i = \\prod_{j \\in \\{1, \\ldots, N \\}\\backslash {i}} \\frac{j}{j - i}$ are the Lagrange coefficients.  \n",
    "Finally, the validity is verified by running $\\text{Verify}_{BLS} (\\text{PK}, \\text{SHA}_{512}(\\text{msg}_{\\text{init}}) , \\sigma_{t} ) $, where $\\text{PK}$ is the global public key.  \n",
    "NB! Please note that the signature share are initially compressed curve points, and in order to use scalar multiplication we uncompress the shares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Combine the signature shares. Use the lagrange_coeff(i,t) function above\n",
    "\n",
    "sig_comb_lst = []\n",
    "# TEST CASE 1\n",
    "print(\"TEST CASE 1\")\n",
    "print(\"===========\")\n",
    "tst_lst = random.sample(range(N),t) # t users randomly selected\n",
    "for i in tst_lst:   \n",
    "    print(\"i = \", i, \", ID = \", i+1, \", sig = \", bn256.g1_uncompress( sigs[i][1] ))\n",
    "#    print(\"1) lambda = \", mod_q(lagrange_coeff(i, tst_lst,t)))\n",
    "#    print(\"2) lambda = \", lagrange_coeff(i, tst_lst,t))\n",
    "    print(\"sig*lambda = \", AnyG1Pointmult( bn256.g1_uncompress( sigs[i][1] ), mod_q(lagrange_coeff(i, tst_lst,t)) ) )\n",
    "    sig_comb_lst.append( AnyG1Pointmult( bn256.g1_uncompress( sigs[i][1] ), mod_q(lagrange_coeff(i, tst_lst,t)) ) )\n",
    "\n",
    "sig_comb = recursive_g1_add(sig_comb_lst)\n",
    "print(\"sigma_t = \", sig_comb)\n",
    "ok = bls_verify(PK, hash_msg_init.encode(\"utf-8\"), bn256.g1_compress(sig_comb) )\n",
    "assert ok\n",
    "\n",
    "\n",
    "sig_comb_lst = []\n",
    "# TEST CASE 2\n",
    "print(\"TEST CASE 2\")\n",
    "print(\"===========\")\n",
    "tst_lst =  random.sample(range(N),t) # t users randomly selected\n",
    "for i in tst_lst:    \n",
    "    print(\"i = \", i, \", ID = \", i+1, \", sig = \", bn256.g1_uncompress( sigs[i][1] ))\n",
    "#    print(\"1) lambda = \", mod_q(lagrange_coeff(i, tst_lst,t)))\n",
    "#    print(\"2) lambda = \", lagrange_coeff(i, tst_lst,t))\n",
    "    print(\"sig*lambda = \", AnyG1Pointmult( bn256.g1_uncompress( sigs[i][1] ), mod_q(lagrange_coeff(i,tst_lst,t)) ) )\n",
    "    sig_comb_lst.append( AnyG1Pointmult( bn256.g1_uncompress( sigs[i][1] ), mod_q(lagrange_coeff(i, tst_lst,t)) ) )\n",
    "\n",
    "sig_comb = recursive_g1_add(sig_comb_lst)\n",
    "print(\"sigma_t = \", sig_comb)\n",
    "ok = bls_verify(PK, hash_msg_init.encode(\"utf-8\"), bn256.g1_compress(sig_comb) )\n",
    "assert ok\n",
    "\n",
    "\n",
    "sig_comb_lst = []\n",
    "# TEST CASE 3\n",
    "print(\"TEST CASE 3\")\n",
    "print(\"===========\")\n",
    "tst_lst =  random.sample(range(N),t) # t users randomly selected\n",
    "for i in tst_lst:    \n",
    "    print(\"i = \", i, \", ID = \", i+1, \", sig = \", bn256.g1_uncompress( sigs[i][1] ))\n",
    "#    print(\"1) lambda = \", mod_q(lagrange_coeff(i, tst_lst,t)))\n",
    "#    print(\"2) lambda = \", lagrange_coeff(i, tst_lst,t))\n",
    "    print(\"sig*lambda = \", AnyG1Pointmult( bn256.g1_uncompress( sigs[i][1] ), mod_q(lagrange_coeff(i, tst_lst,t)) ) )\n",
    "    sig_comb_lst.append( AnyG1Pointmult( bn256.g1_uncompress( sigs[i][1] ), mod_q(lagrange_coeff(i, tst_lst,t)) ) )\n",
    "\n",
    "sig_comb = recursive_g1_add(sig_comb_lst)\n",
    "print(\"sigma_t = \", sig_comb)\n",
    "ok = bls_verify(PK, hash_msg_init.encode(\"utf-8\"), bn256.g1_compress(sig_comb) )\n",
    "assert ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
